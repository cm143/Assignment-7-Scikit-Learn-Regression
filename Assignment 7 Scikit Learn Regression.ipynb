{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
      "         0.01990749, -0.01764613],\n",
      "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
      "        -0.06833155, -0.09220405],\n",
      "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
      "         0.00286131, -0.02593034],\n",
      "       ...,\n",
      "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
      "        -0.04688253,  0.01549073],\n",
      "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
      "         0.04452873, -0.02593034],\n",
      "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
      "        -0.00422151,  0.00306441]]), 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
      "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
      "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
      "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
      "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
      "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
      "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
      "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
      "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
      "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
      "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
      "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
      "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
      "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
      "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
      "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
      "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
      "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
      "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
      "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
      "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
      "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
      "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
      "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
      "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
      "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
      "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
      "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
      "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
      "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
      "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
      "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
      "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
      "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
      "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
      "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
      "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
      "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
      "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
      "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
      "       220.,  57.]), 'frame': None, 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'data_filename': 'diabetes_data_raw.csv.gz', 'target_filename': 'diabetes_target.csv.gz', 'data_module': 'sklearn.datasets.data'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "datasets.load_diabetes()\n",
    "db_data = datasets.load_diabetes()\n",
    "x_data = db_data.data\n",
    "y_data = db_data.target\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size = 0.2, random_state = 20)\n",
    "print(db_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble model explained variance score\n",
      "0.3800138947361539\n",
      "ensemble model maximum error value\n",
      "152.73\n",
      "ensemble model mean absolute error\n",
      "49.14629213483146\n",
      "ensemble model mean squared error\n",
      "3761.9165460674158\n",
      "ensemble model mean squared log error\n",
      "0.22210991785544731\n",
      "ensemble model median absolute error\n",
      "38.74000000000001\n",
      "ensemble model mean absolute percentage error\n",
      "0.48424376313131284\n",
      "ensemble model r2 score\n",
      "0.3674947463468101\n"
     ]
    }
   ],
   "source": [
    "#Model 1#\n",
    "from sklearn import ensemble\n",
    "ensemble_model = ensemble.RandomForestRegressor()\n",
    "ensemble_model.fit(x_train, y_train)\n",
    "ensemble_preds = ensemble_model.predict(x_test)\n",
    "ensemble_preds[ensemble_preds < 0] = 0\n",
    "print(\"ensemble model explained variance score\")\n",
    "print(metrics.explained_variance_score(y_test, ensemble_preds))  \n",
    "print(\"ensemble model maximum error value\")\n",
    "print(metrics.max_error(y_test, ensemble_preds))  \n",
    "print(\"ensemble model mean absolute error\")\n",
    "print(metrics.mean_absolute_error(y_test, ensemble_preds))  \n",
    "print(\"ensemble model mean squared error\")\n",
    "print(metrics.mean_squared_error(y_test, ensemble_preds))\n",
    "print(\"ensemble model mean squared log error\")\n",
    "print(metrics.mean_squared_log_error(y_test, ensemble_preds))\n",
    "print(\"ensemble model median absolute error\")\n",
    "print(metrics.median_absolute_error(y_test, ensemble_preds))\n",
    "print(\"ensemble model mean absolute percentage error\")\n",
    "print(metrics.mean_absolute_percentage_error(y_test, ensemble_preds))\n",
    "print(\"ensemble model r2 score\")\n",
    "print(metrics.r2_score(y_test, ensemble_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear model explained variance score\n",
      "0.4283865665782991\n",
      "linear model maximum error value\n",
      "161.0670564824382\n",
      "linear model mean absolute error\n",
      "47.65391388234144\n",
      "linear model mean squared error\n",
      "3461.6627862550476\n",
      "linear model mean squared log error\n",
      "0.22660140662180792\n",
      "linear model median absolute error\n",
      "40.016549884218705\n",
      "linear model mean absolute percentage error\n",
      "0.48019225273905125\n",
      "linear model r2 score\n",
      "0.4179775463198647\n"
     ]
    }
   ],
   "source": [
    "#Model 2#\n",
    "from sklearn import linear_model\n",
    "lin_model = linear_model.LinearRegression()\n",
    "lin_model.fit(x_train, y_train)\n",
    "linear_preds = lin_model.predict(x_test)\n",
    "linear_preds[linear_preds < 0] = 0\n",
    "print(\"linear model explained variance score\")\n",
    "print(metrics.explained_variance_score(y_test, linear_preds))  \n",
    "print(\"linear model maximum error value\")\n",
    "print(metrics.max_error(y_test, linear_preds))  \n",
    "print(\"linear model mean absolute error\")\n",
    "print(metrics.mean_absolute_error(y_test, linear_preds))  \n",
    "print(\"linear model mean squared error\")\n",
    "print(metrics.mean_squared_error(y_test, linear_preds))\n",
    "print(\"linear model mean squared log error\")\n",
    "print(metrics.mean_squared_log_error(y_test, linear_preds))\n",
    "print(\"linear model median absolute error\")\n",
    "print(metrics.median_absolute_error(y_test, linear_preds))\n",
    "print(\"linear model mean absolute percentage error\")\n",
    "print(metrics.mean_absolute_percentage_error(y_test, linear_preds))\n",
    "print(\"linear model r2 score\")\n",
    "print(metrics.r2_score(y_test, linear_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm explained variance score\n",
      "0.19333040720951788\n",
      "svm maximum error value\n",
      "165.41781935398598\n",
      "svm mean absolute error\n",
      "56.7822847313719\n",
      "svm mean squared error\n",
      "4798.526190508464\n",
      "svm mean squared log error\n",
      "0.29176407389765563\n",
      "svm median absolute error\n",
      "54.35388410603156\n",
      "svm mean absolute percentage error\n",
      "0.574712479104683\n",
      "svm r2 score\n",
      "0.19320564714232746\n"
     ]
    }
   ],
   "source": [
    "#Model 3#\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVR()\n",
    "svm_model.fit(x_train, y_train)\n",
    "svm_preds = svm_model.predict(x_test)\n",
    "svm_preds[svm_preds < 0] = 0\n",
    "print(\"svm explained variance score\")\n",
    "print(metrics.explained_variance_score(y_test, svm_preds))  \n",
    "print(\"svm maximum error value\")\n",
    "print(metrics.max_error(y_test, svm_preds))  \n",
    "print(\"svm mean absolute error\")\n",
    "print(metrics.mean_absolute_error(y_test, svm_preds))  \n",
    "print(\"svm mean squared error\")\n",
    "print(metrics.mean_squared_error(y_test, svm_preds))\n",
    "print(\"svm mean squared log error\")\n",
    "print(metrics.mean_squared_log_error(y_test, svm_preds))\n",
    "print(\"svm median absolute error\")\n",
    "print(metrics.median_absolute_error(y_test, svm_preds))\n",
    "print(\"svm mean absolute percentage error\")\n",
    "print(metrics.mean_absolute_percentage_error(y_test, svm_preds))\n",
    "print(\"svm r2 score\")\n",
    "print(metrics.r2_score(y_test, svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my point of view, the model that worked the best was the linear model. The linear model had the highest r2 score since it was the closest to 1. The linear model had the lowest mean absolute percentage error, lowest mean absolute error, lowest mean squared error and mean squared log error. Since they were all closest to zero, that meant that errors were pretty low, and therefore, fairly accurate to the original data. It also had the highest explained variance score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
